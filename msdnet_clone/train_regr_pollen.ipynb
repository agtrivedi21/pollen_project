{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "523\n",
      "523\n",
      "1000\n",
      "1000\n",
      "474\n",
      "474\n",
      "2997\n",
      "2997\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------------------------\n",
    "#Copyright 2019 Centrum Wiskunde & Informatica, Amsterdam\n",
    "#\n",
    "#Author: Daniel M. Pelt\n",
    "#Contact: D.M.Pelt@cwi.nl\n",
    "#Website: http://dmpelt.github.io/msdnet_clone.\n",
    "#License: MIT\n",
    "#\n",
    "#This file is part of msdnet_clone. a Python implementation of the\n",
    "#Mixed-Scale Dense Convolutional Neural Network.\n",
    "#-----------------------------------------------------------------------\n",
    "\n",
    "\"\"\"\n",
    "Example 01: Train a network for regression\n",
    "==========================================\n",
    "\n",
    "This script trains a MS-D network for regression (i.e. denoising/artifact removal)\n",
    "Run generatedata.py first to generate required training data.\n",
    "\"\"\"\n",
    "\n",
    "# Import code\n",
    "import msdnet_clone\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "NUM_TRAIN = 1000  # number of training images to use per class\n",
    "NUM_VAL = 250    # number of validation images to use per class\n",
    "\n",
    "# Define dilations in [1,10] as in paper.\n",
    "dilations = msdnet_clone.dilations.IncrementDilations(10)\n",
    "\n",
    "# Create main network object for regression, with 100 layers,\n",
    "# [1,10] dilations, 1 input channel, 1 output channel, using\n",
    "# the GPU (set gpu=False to use CPU)\n",
    "n = msdnet_clone.network.MSDNet(100, dilations, 3, 1, gpu=False)\n",
    "\n",
    "# Initialize network parameters\n",
    "n.initialize()\n",
    "\n",
    "# Define training data\n",
    "flsin_1 = sorted(glob.glob('train/1/*.tiff'))\n",
    "flsin_1 = flsin_1[:min(NUM_TRAIN, len(flsin_1))]\n",
    "flstg_1 = []\n",
    "for _ in range(0, len(flsin_1)):\n",
    "    flstg_1.append('train/class1_expectation.tiff')\n",
    "print(len(flsin_1))\n",
    "print(len(flstg_1))\n",
    "\n",
    "flsin_2 = sorted(glob.glob('train/2/*.tiff'))\n",
    "flsin_2 = flsin_2[:min(NUM_TRAIN, len(flsin_2))]\n",
    "flstg_2 = []\n",
    "for _ in range(0, len(flsin_2)):\n",
    "    flstg_2.append('train/class2_expectation.tiff')\n",
    "print(len(flsin_2))\n",
    "print(len(flstg_2))\n",
    "\n",
    "flsin_3 = sorted(glob.glob('train/3/*.tiff'))\n",
    "flsin_3 = flsin_3[:min(NUM_TRAIN, len(flsin_3))]\n",
    "flstg_3 = []\n",
    "for _ in range(0, len(flsin_3)):\n",
    "    flstg_3.append('train/class3_expectation.tiff')\n",
    "print(len(flsin_3))\n",
    "print(len(flstg_3))\n",
    "\n",
    "flsin_4 = sorted(glob.glob('train/4/*.tiff'))\n",
    "flsin_4 = flsin_4[:min(NUM_TRAIN, len(flsin_4))]\n",
    "flstg_4 = []\n",
    "for _ in range(0, len(flsin_4)):\n",
    "    flstg_4.append('train/class4_expectation.tiff')\n",
    "print(len(flsin_4))\n",
    "print(len(flstg_4))\n",
    "\n",
    "flsin = flsin_1 + flsin_2 + flsin_3 + flsin_4\n",
    "flstg = flstg_1 + flstg_2 + flstg_3 + flstg_4\n",
    "print(len(flsin))\n",
    "print(len(flstg))\n",
    "\n",
    "# Create list of datapoints (i.e. input/target pairs)\n",
    "dats = []\n",
    "for i in range(len(flsin)):\n",
    "    # Create datapoint with file names\n",
    "    d = msdnet_clone.data.ImageFileDataPoint(str(flsin[i]),str(flstg[i]))\n",
    "    # Augment data by rotating and flipping\n",
    "    d_augm = msdnet_clone.data.RotateAndFlipDataPoint(d)\n",
    "    # Add augmented datapoint to list\n",
    "    dats.append(d_augm)\n",
    "# Note: The above can also be achieved using a utility function for such 'simple' cases:\n",
    "# dats = msdnet_clone.utils.load_simple_data('train/noisy/*.tiff', 'train/noiseless/*.tiff', augment=True)\n",
    "\n",
    "# Normalize input and output of network to zero mean and unit variance using\n",
    "# training data images\n",
    "n.normalizeinout(dats)\n",
    "\n",
    "# Use image batches of a single image\n",
    "bprov = msdnet_clone.data.BatchProvider(dats,32)\n",
    "\n",
    "# Define validation data (not using augmentation)\n",
    "flsin_1 = sorted(glob.glob('val/1/*.tiff'))\n",
    "flsin_1 = flsin_1[:min(NUM_VAL, len(flsin_1))]\n",
    "flstg_1 = []\n",
    "for _ in range(0, len(flsin_1)):\n",
    "    flstg_1.append('val/class1_expectation.tiff')\n",
    "print(len(flsin_1))\n",
    "print(len(flstg_1))\n",
    "flsin_2 = sorted(glob.glob('val/2/*.tiff'))\n",
    "flsin_2 = flsin_2[:min(NUM_VAL, len(flsin_2))]\n",
    "flstg_2 = []\n",
    "for _ in range(0, len(flsin_2)):\n",
    "    flstg_2.append('val/class2_expectation.tiff')\n",
    "print(len(flsin_2))\n",
    "print(len(flstg_2))\n",
    "flsin_3 = sorted(glob.glob('val/3/*.tiff'))\n",
    "flsin_3 = flsin_3[:min(NUM_VAL, len(flsin_3))]\n",
    "flstg_3 = []\n",
    "for _ in range(0, len(flsin_3)):\n",
    "    flstg_3.append('val/class3_expectation.tiff')\n",
    "print(len(flsin_3))\n",
    "print(len(flstg_3))\n",
    "flsin_4 = sorted(glob.glob('val/4/*.tiff'))\n",
    "flsin_4 = flsin_4[:min(NUM_VAL, len(flsin_4))]\n",
    "flstg_4 = []\n",
    "for _ in range(0, len(flsin_4)):\n",
    "    flstg_4.append('val/class4_expectation.tiff')\n",
    "print(len(flsin_4))\n",
    "print(len(flstg_4))\n",
    "flsin = flsin_1 + flsin_2 + flsin_3 + flsin_4\n",
    "flstg = flstg_1 + flstg_2 + flstg_3 + flstg_4\n",
    "print(len(flsin))\n",
    "datsv = []\n",
    "for i in range(len(flsin)):\n",
    "    d = msdnet_clone.data.ImageFileDataPoint(str(flsin[i]),str(flstg[i]))\n",
    "    datsv.append(d)\n",
    "# Note: The above can also be achieved using a utility function for such 'simple' cases:\n",
    "# datsv = msdnet_clone.utils.load_simple_data('val/noisy/*.tiff', 'val/noiseless/*.tiff', augment=False)\n",
    "\n",
    "# Select loss function\n",
    "l2loss = msdnet_clone.loss.L2Loss()\n",
    "\n",
    "# Validate with loss function\n",
    "val = msdnet_clone.validate.LossValidation(datsv, loss=l2loss)\n",
    "\n",
    "# Use ADAM training algorithms\n",
    "t = msdnet_clone.train.AdamAlgorithm(n, loss=l2loss)\n",
    "\n",
    "# Log error metrics to console\n",
    "consolelog = msdnet_clone.loggers.ConsoleLogger()\n",
    "# Log error metrics to file\n",
    "filelog = msdnet_clone.loggers.FileLogger('log_regr.txt')\n",
    "# Log typical, worst, and best images to image files\n",
    "imagelog = msdnet_clone.loggers.ImageLogger('log_regr', onlyifbetter=True)\n",
    "\n",
    "# Train network until program is stopped manually\n",
    "# Network parameters are saved in regr_params.h5\n",
    "# Validation is run after every len(datsv) (=25)\n",
    "# training steps.\n",
    "msdnet_clone.train.train(n, t, val, bprov, 'regr_params.h5',loggers=[consolelog,filelog,imagelog], val_every=len(datsv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a8b483bce0fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mclass_1_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m83\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n' is not defined"
     ]
    }
   ],
   "source": [
    "flsin_4 = sorted(glob.glob('train/4/*.tiff'))\n",
    "datapoints = []\n",
    "for i in range(20):\n",
    "    datapoints.append(msdnet_clone.data.ImageFileDataPoint(str(flsin_4[i]))) # all class 3 images\n",
    "outputs = []\n",
    "for i in range(20):\n",
    "    outputs.append(n.forward(datapoints[i].input))\n",
    "for i in range(20):\n",
    "    class_1_space = outputs[i][0][:21, 0:83]\n",
    "    class_1_score = np.sum(class_1_space)\n",
    "    class_2_space = outputs[i][0][22:42, 0:83]\n",
    "    class_2_score = np.sum(class_2_space)\n",
    "    class_3_space = outputs[i][0][43:63, 0:83]\n",
    "    class_3_score = np.sum(class_3_space)\n",
    "    class_4_space = outputs[i][0][64:84, 0:83]\n",
    "    class_4_score = np.sum(class_4_space)\n",
    "    print(len(outputs[i]))\n",
    "    print(\"class 1 score: \" + str(class_1_score))\n",
    "    print(\"class 2 score: \" + str(class_2_score))\n",
    "    print(\"class 3 score: \" + str(class_3_score))\n",
    "    print(\"class 4 score: \" + str(class_4_score))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
